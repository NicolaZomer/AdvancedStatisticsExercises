---
title: "Exercises Laboratory Session 04"
author: "Nicola Zomer"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document: default
---

```{r setup-chunk}
knitr::opts_chunk$set(dev = "ragg_png")
options(digits=5) # set number of digits equal to 5

```

# Packages and functions

```{r, message=FALSE}

# tidyverse
library(tidyverse)

# others
library(kableExtra)
library(patchwork)
library(ggpubr)
library(latex2exp)
#library(gridExtra)
#library(glue)

```


# Exercise 1 - Community Mobility Open Data
Community Mobility Reports have been created with the aim to provide insights into what has changed in response to policies aimed at combating COVID-19. Data can be found at https://www.google.com/covid19/mobility/.

Download and analyze the following data sets:

* https://www.gstatic.com/covid19/mobility/Global_Mobility_Report.csv 
* https://www.gstatic.com/covid19/mobility/Region_Mobility_Report_CSVs.zip

Select a couple of European countries of your choice and analyze the trends in the variables over time: produce a plot of the data by averaging the observable over a period of one week (hint: convert the data field to `lubridate::week`) and one month and quantify the impact of COVID-19 restrictions on mobility situations.

```{r}



```


# Exercise 2 - Random number generators
One of the first random number generator was proposed by von Neumann, the so-called _middle square_ algorithm. 

Write R code to implement this type of generator and, given a fixed digit number input, square it an remove the leading and trailing digits, in order to return a number with the same number of digits as the original number.

```{r}

middle_square <- function(x.start=5772156649, n){
  input.digits <- length(unlist(strsplit(as.character(x.start),"")))
  
  # print(paste('Number of digits of the input number:', input.digits))
  if (x.start%%1 != 0) stop('The starting number must be integer')
  
  x.squared.char <- unlist(strsplit(as.character(x.start^2),""))  
  half.output.digits <- length(x.squared.char)%/%2
  
  if (input.digits%%2 ==0){ # even number of digits
    x.i <- x.squared.char[(half.output.digits-(input.digits/2-1)):(half.output.digits+input.digits/2)]
  } else{ # odd number of digits
    x.i <- x.squared.char[(half.output.digits-(input.digits%/%2)):(half.output.digits+input.digits%/%2)]
  }
  
  # check if the first digit is zero: in this case shift to the left
  i<-1
  while (x.i[1]=="0"){
    print(x.i)
    if (input.digits%%2 ==0){ # even number of digits
      x.i <- x.squared.char[(half.output.digits-(input.digits/2-1)-i):(half.output.digits+input.digits/2-i)]
    } else{ # odd number of digits
      x.i <- x.squared.char[(half.output.digits-(input.digits%/%2)-i):(half.output.digits+input.digits%/%2-i)]
    }
    i<-i+1
  }
  return(as.numeric(paste(x.i, collapse="")))
}

```

Generate 10 numbers using the _middle square_ algorithm:
```{r}

numbers <- numeric(11)
numbers[1] <- 5772156649

for (i in 1:10){
  numbers[i+1] <- middle_square(numbers[i])
}

data.frame(Iteration=0:10, Generated.Number=numbers) %>%
  kable() %>%
  kable_styling(full_width=FALSE)

```

# Exercise 3 - Bayesian Inference

A publishing company has recently launched a new journal. In order to determine how effective it is in reaching its possible audience, a market survey company selects a random sample of people from a possible target audience and interviews them. Out of 150 interviewed people, 29 have read the last issue of the journal.

### a) What kind of distribution would you assume for y, the number of people that have seen the last issue of the journal?

```{r}


```

### b) Assuming a uniform prior, what is the posterior distribution for y ?

```{r}


```

### c) Plot both posterior and likelihood ditributions functions

```{r}


```


# Exercise 4 - Bayesian Inference
A coin is flipped n = 30 times with the following outcomes:

T, T, T, T, T, H, T, T, H, H, T, T, H, H, H, T, H, T, H, T, H, H, T, H, T, H, T, H, H, H

Notice that there are 15 T and 15 H

### a) Assuming a flat prior, and a beta prior, plot the likelihood, prior and posterior distributions for the data set.

```{r}

n <- 30
r <- 15

nsamples <- 200
p <- seq(0, 1, length = nsamples)
delta.p <- 1/nsamples

unif.post <- dbinom(x=r, size=n, prob=p)
unif.post.norm <- unif.post/(delta.p*sum(unif.post))

ggplot()+
  geom_line(aes(x=p, y=unif.post.norm, color='Posterior and likelihood'), size=0.6)+
  geom_line(aes(x=p, y=dunif(p), color='Prior'), size=0.6)+
  labs(
    title='Flat prior', 
    x='p', 
    y=TeX('$P(p|r,n, M)$')
  )+
  scale_color_manual(name = "", values = c("Posterior and likelihood" = "steelblue", "Prior" = "firebrick"))+
  theme(legend.title= element_blank())+
  theme_bw()

```
```{r, fig.height=18, fig.width=18}

alpha <- 10; beta <- 10


gg_beta <- function(alpha, beta){
  ggplot()+
    geom_line(aes(x=p, y=dbeta(x=p, alpha+r, beta+n-r), color='Posterior'), size=1)+
    geom_line(aes(x=p, y=dbinom(x=r, size=n, prob=p), color='Likelihood'), size=1)+
    geom_line(aes(x=p, y=dbeta(p, alpha , beta), color='Prior'), size=1)+
    labs(
      title=paste('Beta prior (', alpha, ', ', beta, ')', sep=''), 
      x='p', 
      y=TeX('$P(p|r,n, M)$')
    )+
    scale_color_manual(name = "", values = c("Posterior" = "steelblue", "Likelihood"= "darkgreen", "Prior" = "firebrick"))+
    theme_bw()+
    theme(legend.title = element_blank(), 
          plot.title  = element_text(size=22), 
          axis.text   = element_text(size=18),
          axis.title  = element_text(size=18), 
          legend.text = element_text(size=22))
}

combined <- (gg_beta(1,1) +ylim(0,6) + gg_beta(1,5) +ylim(0,6) + gg_beta(1,10) +ylim(0,10) )/
            (gg_beta(5,1) +ylim(0,6) + gg_beta(5,5) +ylim(0,6) + gg_beta(5,10) +ylim(0,6))/ 
            (gg_beta(10,1)+ylim(0,10)+ gg_beta(10,5)+ylim(0,6) + gg_beta(10,10)+ylim(0,6)) & theme(legend.position = "bottom")

combined + plot_layout(guides = "collect")



```


### b) Evaluate the most probable value for the coin probability p and, integrating the posterior probability distribution, give an estimate for a 95% credibility interval.

```{r}


```

### c) Repeat the same analysis assuming a sequential analysis of the data. Show how the most probable value and the credibility interval change as a function of the number of coin tosses (i.e. from 1 to 30).

```{r}

```

### d) Do you get a different result, by analyzing the data sequentially with respect to a one-step analysis (i.e. considering all the data as a whole)?

```{r}

```













